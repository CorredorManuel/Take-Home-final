---
title: "Simulación cointegración y MCE"
date: "24-05-2022"
author: "Valentina Ortiz, Miguel Luna, Angie Gómez"
output: html_notebook
---

## Simulación tres variables cointegradas 

El modelo planteado para analizar la cointegración será el modelo de crecimiento económico de Solow, el cual, plantea la relación a largo plazo entre los niveles de producción de una economía y los niveles de acumulación de capital y trabajo. El modelo parte de una función Cobb-Douglas de la siguiente manera:`Y=K^αL^{1-α}`. El modelo plantea que en largo plazo las economías convergen a un estado estacionario y que el crecimiento a largo plazo solo se logra a través del progreso tecnológico. Solow plantea que existen diferencias entre el crecimiento de países ricos y pobres, y existe una convergencia, donde los países pobres crecen a una tasa mayor que los países ricos. Las diferencias logran reducirse gracias a la difusión del conocimiento y de la asignación eficiente de los flujos de capital.

**1. Creación de las tres variables**

La primera variable es:
$$
X_t= X_{t-1}+\varepsilon_{xt}\\
Donde \ \varepsilon_{xt} \ es \ ruido \ blanco
$$
La segunda variable es:
$$
Y_t= Y_{t-1}+\varepsilon_{yt} \\
Donde \ \varepsilon_{yt} \ es \ ruido \ blanco
$$
Creación de variable de paso:
$$
U_t= \phi U_{t-1}+\varepsilon_{Ut} \\
Donde \ \varepsilon_{yt} \ es \ ruido \ blanco \ y \ |\phi|<1
$$
Finalmente simular la última variable que depende de la variable:
$$
W_t= \alpha+\phi_1 X_t+\phi_2Y_t+U_t \\
Donde \ U_{t} \  es \ ruido \ blanco
$$

```{r}
#Libraries
library(ggplot2)
library(dplyr)
library(hrbrthemes)
library(lubridate)
library(plotly)
#Crear los valores iniciales para X_t
n <- 500
Xo <- 2


#Establecer semilla y crear los residuales
set.seed(6352)
residualesx <- c(rnorm(n, mean=0, sd=20))
#Crear X_t que provienen de un DGP 4
SerieX_t <- c()
SerieX_t[1] <- Xo
for (i in 2:n) {
    SerieX_t[i] <- SerieX_t[i-1]+residualesx[i-1]
}


#Crear los valores iniciales para U_t
Uo <- 9
Phi <- 0.3
#Establecer semilla y crear los residuales
set.seed(1548)
residualesu <- c(rnorm(n, mean=0, sd=30))
#Crear la variable de paso U_t etacionaria
SerieU_t <- c()
#Establecer U[1]=El valor incial
SerieU_t[1] <- Uo
for (i in 2:n) {
SerieU_t[i] <- Phi*SerieU_t[i-1]+residualesu[i-1]
}



#Crear la variable Y_t con valores inciales
Yo <- 7
#Establecer semilla y crear los residuales
set.seed(6789)
residualesy <- c(rnorm(n, mean=0, sd=21))
#Crear X_t que provienen de un DGP 4
SerieY_t <- c()
#Establecer X[1]=El valor incial
SerieY_t[1] <- Yo
for (i in 2:n) {
SerieY_t[i] <- SerieY_t[i-1]+residualesy[i-1]
}
SerieW_t <- c()
for (i in 1:n) {
SerieW_t[i] <- 10+0.4*SerieX_t[i]+0.6*SerieY_t[i]+SerieU_t[i]
}

Series <- data.frame(seriex=SerieX_t, seriey=SerieY_t,seriew=SerieW_t, t=seq(1:n))

Grafica <- ggplot(Series)+
    geom_line(aes(x=t,y=seriex), color="cadetblue3", size=1)+
    geom_line(aes(x=t,y=seriey), color="chocolate3", size=1)+
    geom_line(aes(x=t,y=seriew), color="salmon", size=1)+
    theme_ipsum()+
    ylab("Datos")+
    xlab("T")+
    ggtitle("Gráfico de tres series cointegradas")

Grafica <- ggplotly(Grafica)
Grafica
```


## 2. Verificación de la existencia de cointegración

**Definición formal de Cointegración:**
La cointegración entre dos o más series de tiempo significa que estas comparten una tendencia estocástica común, entonces, las variables presentan una relación fuerte a largo plazo. De hecho, Stock y Watson (1988) demuestran que las variables cointegradas comparten dicha tendencia que es eliminada por un vector de cointegración.

### 2.1 Existencia de raiz unitaria

La existencia de cointegración esta relacionada con la necesidad de raiz unitaria en cada una de las variables. Para esto se realizan pruebas de contraste, en este caso, Dickey Fuller.

**Prueba de existencia de raiz unitaria DF**

En primer lugar se deben contemplar los 3 esquemas posibles:
$$
\Delta Y_t=\gamma Y_{t-1}+\sum_{i=2}^{p}\beta_i\Delta Y_{t-i+1}+ \varepsilon_t\\
\Delta Y_t=\alpha +\gamma Y_{t-1}+\sum_{i=2}^{p}\beta_i\Delta Y_{t-i+1}+\varepsilon_t\\
\Delta Y_t=\alpha +\beta t+\gamma Y_{t-1}+\sum_{i=2}^{p}\beta_i\Delta Y_{t-i+1}+\varepsilon_t
$$
Encontrar el p que es significativo, para determinar si estamos en un Dickey Fuller o un Dickey Fuller aumentado.A la vez se tiene que cumplir con ruido blanco en los residuales.

```{r}
#Se crea una función para comprobar el ruido blanco de los residuales de cada estimación
ljungbox<-function(residuales){
N<-length(residuales)
k<-N/4
test_ruido<-Box.test(residuales,lag = k,type = "Ljung-Box")
return(test_ruido$p.value)
}

#Se crea una función p que al determinar un p máximo el vaya calculando la significancia a un nivel alpha determinado
p<-function(Pmax,serie,alpha){
deltay<-diff(serie)
significancias<-c()
ruidoblanco<-c()
valorc<-c()
rbestadistico<-c()
for(i in 1:Pmax){
yd<-deltay[(i+1):length(deltay)]
n<-length(yd)
X<-matrix(data=0,n,i+3)
X[,1]<-1
X[,2]<-c(1:n)
X[,3]<-serie[(i+1):(length(serie)-1)]
for(j in 1:i){
X[,(j+3)]<-deltay[((i+1)-j):(length(deltay)-j)]
}
Betas<-solve(t(X)%*%X)%*%t(X)%*%yd
y_e<-X%*%Betas
e_e<-(yd-y_e)
sigma <- as.numeric((t(e_e)%*%e_e))/(n-ncol(X))
varcov<- sigma*(solve(t(X)%*%X))
t1<-abs(Betas[ncol(X)]/sqrt(varcov[ncol(X),ncol(X)]))
significancias[i]<-t1
valorc[i]<-qt(1-(alpha/2),n)
ruidoblanco[i]<-ljungbox(e_e)
rbestadistico[i]<-alpha
VC<-cbind(significancias,valorc,ruidoblanco,rbestadistico)
}
contador<-c()
#Revisar desigualdades y ljungbox pvalues
for( i in 1:Pmax){
if(VC[i,1]<VC[i,2] & VC[i,3]<VC[i,4] ){
contador[i]<-1 # ruido blanco y signifcancia
}else{
contador[i]<-0
}
}
return(contador)
}

#Evaluaremos con p maximo de 15
RezagosW <- p(Pmax=30, serie=matriz, alpha=0.05)
RezagosW <- p(Pmax=15, serie=SerieW_t, alpha=0.05)
RezagosX <- p(Pmax=15, serie=SerieX_t, alpha=0.05)
RezagosY <- p(Pmax=15, serie=SerieY_t, alpha=0.05)

RezagosW
RezagosX
RezagosY
```
De acuerdo con el resultado, ningún rezago igual a 2 o mayor es significativo. Se deduce que el rezago que genera ruido blanco y es significativo es p=1.
No requiere de parte aumentada, así pues:

$$
\Delta Y_t=\alpha +\beta t+\gamma Y_{t-1}+\varepsilon_t
$$
Ya teniendo el nuevo esquema, sin la parte aumentada, es necesario estimar por OLS y hallar la significancia de cada coeficiente. Se empezará por el gamma, que nos diría si hay o no hay raíz unitaria.

```{r}
p <- 1
W_t_menos_1 <- c()
for (i in 1:n) {
W_t_menos_1[i] <- SerieW_t[i-1]
}
N3 <- length(W_t_menos_1)-1
#creo el delta
DeltaW<- c()
for (i in 1:n) {
DeltaW[i]<- SerieW_t[i]-W_t_menos_1[i]
}

DeltaW_cuchilla <- as.matrix(DeltaW[(p+1):length(DeltaW)])
#Estimacion
X_W3DF <- matrix(0,N3,p+2)
X_W3DF[,1]=1 #Intercepto
X_W3DF[,2]=1:length(X_W3DF[,1]) #Tendencia
X_W3DF[,3]=SerieW_t[(p+1):length(SerieW_t)-1] #Rezago de la serie

BetasW3 <- solve(as.matrix(t(X_W3DF)%*%X_W3DF))%*%t(X_W3DF)%*%DeltaW_cuchilla
Westimado3 <- X_W3DF%*%BetasW3
ResidualesW3 <- DeltaW_cuchilla-Westimado3
SigmaW3 <- as.numeric(t(ResidualesW3)%*%ResidualesW3)/(length(DeltaW_cuchilla)-ncol(X_W3DF))
VarcovW3 <- SigmaW3*(solve(t(X_W3DF)%*%X_W3DF))

AlphaW3 <- BetasW3[1]
BetaW3 <- BetasW3[2]
GammaW3 <- BetasW3[3]
```

Pruebo la significancia del gamma con ayuda de los valores críticos simulados de los Taus.

Simulaciones de los Taus, se realizan por medio de una función:

```{r}
#tau toma el valor de 1, es distribución tau, 2 es distribución tau-mu y 3 si es distribución tau-tau
Distribucion_tau <- function(N,P,tau){

Taus <- c()
Taus_mu <- c()
Taus_tau <- c()
for (q in 1:P) {
e <- rnorm(N,0,1)
Y_0 <- 0
#crear y_t=Y_{t-1}+e_t
Y_t <- matrix(NA,N,1)
for (i in 1:N) {
if(i==1){
Y_t[1] <- Y_0+e[i]
}else{
Y_t[i] <- Y_t[i-1]+e[i]
}
}
#quitar la primeras observaciones para que el modelo no dependa del valor inicial
serie <- c(Y_t[(N-(N/5)):N])
n <- length(serie)
#creo el vector y_{t-1}
Y_t_menos_1 <- c()
for (i in 1:n) {
Y_t_menos_1[i] <- serie[i-1]
}
#creo el delta
delta_Y_t <- c()
for (i in 1:n) {
delta_Y_t[i]<- serie[i]-Y_t_menos_1[i]
}
#crear el modelo
#pasamos cuchilla para quitar valor de omision

DISTRIBUCION <- c()
DISTRIBUCION <-
if(tau==1){
Y_1<- (delta_Y_t[2:length(delta_Y_t)])
X_1 <- serie[1:n-1]
gamma_1 <-solve(t(X_1)%*%X_1)%*%t(X_1)%*%Y_1
k <- 1
#Y GORRO
Ygorro_1 <- X_1%*%gamma_1
#ERROR ESTIMADO
egorro_1 <- Y_1-Ygorro_1
#ESTIMADOR PARA VARIANZA
Var_gorro_1 <- as.numeric((t(egorro_1)%*%egorro_1)/(n-1-k))
#VAR-COV(BETA_GORRO)
var_cov_1 <- Var_gorro_1*(solve(t(X_1)%*%X_1))
#desviacion estandar de gamma
desv_gamma_1 <- sqrt(var_cov_1)
#PRUEBA DE TAU-MU TIPO T
Taus[q]<- gamma_1/desv_gamma_1
DISTRIBUCION <- Taus
}
else{
if(tau==2){
Y_2 <- (delta_Y_t[2:length(delta_Y_t)])
X_2 <- cbind(1,serie[1:n-1])
parametros <-solve(t(X_2)%*%X_2)%*%t(X_2)%*%Y_2
gamma_2 <- parametros[2,1]
k <- ncol(X_2)
#Y GORRO
Ygorro_2 <- X_2%*%parametros
#ERROR ESTIMADO
egorro_2 <- Y_2-Ygorro_2
#ESTIMADOR PARA VARIANZA
Var_gorro_2 <- as.numeric((t(egorro_2)%*%egorro_2)/(n-1-k))
#VAR-COV(BETA_GORRO)
var_cov_2 <- Var_gorro_2*(solve(t(X_2)%*%X_2))
#desviacion estandar de gamma
desv_gamma_2 <- sqrt(var_cov_2[2,2])
#PRUEBA DE TAU-MU TIPO T
Taus_mu[q]<- gamma_2/desv_gamma_2
DISTRIBUCION <- Taus_mu
}else{
if(tau==3){
B <- c(seq(2:n))
Y_3 <- (delta_Y_t[2:length(delta_Y_t)])
X_3 <- cbind(1,B,serie[1:n-1])
parametros <-solve(t(X_3)%*%X_3)%*%t(X_3)%*%Y_3
gamma_3 <- parametros[3,1]
k <- ncol(X_3)
#Y GORRO
Ygorro_3 <- X_3%*%parametros
#ERROR ESTIMADO
egorro_3 <- Y_3-Ygorro_3
#ESTIMADOR PARA VARIANZA
Var_gorro_3 <- as.numeric((t(egorro_3)%*%egorro_3)/(n-1-k))
#VAR-COV(BETA_GORRO)
var_cov_3 <- Var_gorro_3*(solve(t(X_3)%*%X_3))
#desviacion estandar de gamma
desv_gamma_3 <- sqrt(var_cov_3[3,3])
#PRUEBA DE TAU-MU TIPO T
Taus_tau[q]<- gamma_3/desv_gamma_3
DISTRIBUCION <- Taus_tau
}
}
}
}
return(DISTRIBUCION)
}
#En este caso, se toma tau-tau porque estamos en el tercer esquema 
DistribucionW3 <- Distribucion_tau(200,1000,3)
tau_graph <- data.frame(w=DistribucionW3)

grafico_tau <- tau_graph%>%
ggplot( aes(x=w)) +
geom_histogram(binwidth=0.3, fill="#69b3a2", color="#e9ecef", alpha=0.9)+
ylab("Frecuencia") +
xlab("t-statistic")+
theme_ipsum()+
theme(plot.title = element_text(size=15))+
#geom_vline(xintercept = q , linetype=2, color="green")+
ggtitle("Distribución Dickey-Fuller")

grafico_tau <- ggplotly(grafico_tau)
grafico_tau
```

Calculamos el valor critico de acuerdo al tau correspondiente, para hacerlo, se hace uso de un función de densidad que ayude a poder calcular la probabilidad acumulada.

```{r}
grafico_tau <- tau_graph%>%
ggplot( aes(x=w)) +
geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.9)+
ylab("Frecuencia") +
xlab("t-statistic")+
theme_ipsum()+
theme(plot.title = element_text(size=15))+
#geom_vline(xintercept = q , linetype=2, color="green")+
ggtitle("Distribución Dickey-Fuller")

grafico_tau <- ggplotly(grafico_tau)
grafico_tau
```
Valor crítico para el Tau-Tau:
```{r}
alpha <- 0.01
x <- sort(DistribucionW3)
cum.dens.fun <- 1:length(x)/length(x)
prob <- (x[which(cum.dens.fun <= alpha)])
VCGammaW3<- prob[length(prob)]
VCGammaW3
```
Estadístico tipo t de Gamma:
```{r}
estadisticoW3Gamma <- GammaW3/(sqrt(VarcovW3[3,3]))
estadisticoW3Gamma
```
Como en este caso, la hipótesis nula es que gamma es estadísticamente igual a cero, por lo tanto, en la hipótesis nula gamma, es estadísticamente diferente de cero. Con el resultado anterior, caemos en la hipótesis nula, por ende existe raíz unitaria.

Ahora concluimos sobre la tendencia y el intercepto comparando con el estadístico tipo t de cada coeficiente con el valor crítico de un t con t-k grados de libertad.

Estadístico tipo t de Beta:
```{r}
estadisticoW3Beta <- BetaW3/(sqrt(VarcovW3[2,2]))
estadisticoW3Beta

VCBetaW3 <- qt((1-alpha),(n/4))
VCBetaW3
```
En este caso, la tendencia no es significativa. Por ende, debemos bajarnos de al esquema 2.

$$
\Delta Y_t=\alpha +\gamma Y_{t-1}+\varepsilon_t
$$
```{r}
p <- 1
W_t_menos_1 <- c()
for (i in 1:n) {
W_t_menos_1[i] <- SerieW_t[i-1]
}
N3 <- length(W_t_menos_1)-1
#creo el delta
DeltaW<- c()
for (i in 1:n) {
DeltaW[i]<- SerieW_t[i]-W_t_menos_1[i]
}

DeltaW_cuchilla <- as.matrix(DeltaW[(p+1):length(DeltaW)])
#Estimacion
X_W3DF <- matrix(0,N3,p+1)
X_W3DF[,1]=1 #Intercepto
X_W3DF[,2]=SerieW_t[(p+1):length(SerieW_t)-1] #Rezago de la serie

BetasW3 <- solve(as.matrix(t(X_W3DF)%*%X_W3DF))%*%t(X_W3DF)%*%DeltaW_cuchilla
Westimado3 <- X_W3DF%*%BetasW3
ResidualesW3 <- DeltaW_cuchilla-Westimado3
SigmaW3 <- as.numeric(t(ResidualesW3)%*%ResidualesW3)/(length(DeltaW_cuchilla)-ncol(X_W3DF))
VarcovW3 <- SigmaW3*(solve(t(X_W3DF)%*%X_W3DF))

AlphaW3 <- BetasW3[1]
GammaW3 <- BetasW3[2]
```


```{r}
#tau toma el valor de 1, es distribución tau, 2 es distribución tau-mu y 3 si es distribución tau-tau
#En este caso, se toma tau-mu porque estamos en el segundo esquema 
DistribucionW3 <- Distribucion_tau(200,1000,2)
tau_graph <- data.frame(w=DistribucionW3)

grafico_tau <- tau_graph%>%
ggplot( aes(x=w)) +
geom_histogram(binwidth=0.3, fill="#69b3a2", color="#e9ecef", alpha=0.9)+
ylab("Frecuencia") +
xlab("t-statistic")+
theme_ipsum()+
theme(plot.title = element_text(size=15))+
#geom_vline(xintercept = q , linetype=2, color="green")+
ggtitle("Distribución Dickey-Fuller")

grafico_tau <- ggplotly(grafico_tau)
grafico_tau
```

Calculamos el valor critico de acuerdo al tau correspondiente, para hacerlo, se hace uso de un función de densidad que ayude a poder calcular la probabilidad acumulada.

```{r}
grafico_tau <- tau_graph%>%
ggplot( aes(x=w)) +
geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.9)+
ylab("Frecuencia") +
xlab("t-statistic")+
theme_ipsum()+
theme(plot.title = element_text(size=15))+
#geom_vline(xintercept = q , linetype=2, color="green")+
ggtitle("Distribución Dickey-Fuller")

grafico_tau <- ggplotly(grafico_tau)
grafico_tau
```
Valor crítico para el Tau-Tau:
```{r}
alpha <- 0.01
x <- sort(DistribucionW3)
cum.dens.fun <- 1:length(x)/length(x)
prob <- (x[which(cum.dens.fun <= alpha)])
VCGammaW3<- prob[length(prob)]
VCGammaW3
```
Estadístico tipo t de Gamma:
```{r}
estadisticoW3Gamma <- GammaW3/(sqrt(VarcovW3[2,2]))
estadisticoW3Gamma
```
Con el resultado anterior, caemos en la hipótesis nula, por ende existe raíz unitaria.

Ahora, es necesario verificar la significancia del intercepto.

```{r}

estadisticoW3Alpha <- AlphaW3/(sqrt(VarcovW3[1,1]))
estadisticoW3Alpha

VCAlphaW3 <- qt((1-alpha),(n/4))
VCAlphaW3
```
Con el resultado anterior, caemos en la hipótesis alterna, por ende el intercepto es significativo.
El resultado es que la serie es una caminata aleatoria sin deriva.

La serie siguiente serie a evaluar es Xt emepzando de nuevo sobre el esquema más amplio.

$$
\Delta Y_t=\alpha +\beta t+\gamma Y_{t-1}+\varepsilon_t
$$

Ya teniendo el nuevo esquema, sin la parte aumentada, es necesario estimar por OLS y hallar la significancia de cada coeficiente. Se empezará por el gamma, que nos diría si hay o no hay raíz unitaria.

```{r}
p <- 1
X_t_menos_1 <- c()
for (i in 1:n) {
X_t_menos_1[i] <- SerieX_t[i-1]
}
N3 <- length(X_t_menos_1)-1
#creo el delta
DeltaX<- c()
for (i in 1:n) {
DeltaX[i]<- SerieX_t[i]-X_t_menos_1[i]
}

DeltaX_cuchilla <- as.matrix(DeltaX[(p+1):length(DeltaX)])
#Estimacion
X_X3DF <- matrix(0,N3,p+2)
X_X3DF[,1]=1 #Intercepto
X_X3DF[,2]=1:length(X_X3DF[,1]) #Tendencia
X_X3DF[,3]=SerieX_t[(p+1):length(SerieX_t)-1] #Rezago de la serie

BetasX3 <- solve(as.matrix(t(X_X3DF)%*%X_X3DF))%*%t(X_X3DF)%*%DeltaX_cuchilla
Xestimado3 <- X_X3DF%*%BetasX3
ResidualesX3 <- DeltaX_cuchilla-Xestimado3
SigmaX3 <- as.numeric(t(ResidualesX3)%*%ResidualesX3)/(length(DeltaX_cuchilla)-ncol(X_X3DF))
VarcovX3 <- SigmaX3*(solve(t(X_X3DF)%*%X_X3DF))

AlphaX3 <- BetasX3[1]
BetaX3 <- BetasX3[2]
GammaX3 <- BetasX3[3]
```

Pruebo la significancia del gamma con ayuda de los valores críticos simulados de los Taus.

Simulaciones de los Taus, se realizan por medio de una función:

```{r}
#tau toma el valor de 1, es distribución tau, 2 es distribución tau-mu y 3 si es distribución tau-tau
#En este caso, se toma tau-tau porque estamos en el tercer esquema 
DistribucionX3 <- Distribucion_tau(200,1000,3)
tau_graph <- data.frame(x=DistribucionX3)

grafico_tau <- tau_graph%>%
ggplot( aes(x=x)) +
geom_histogram(binwidth=0.3, fill="#69b3a2", color="#e9ecef", alpha=0.9)+
ylab("Frecuencia") +
xlab("t-statistic")+
theme_ipsum()+
theme(plot.title = element_text(size=15))+
#geom_vline(xintercept = q , linetype=2, color="green")+
ggtitle("Distribución Dickey-Fuller")

grafico_tau <- ggplotly(grafico_tau)
grafico_tau
```

Calculamos el valor critico de acuerdo al tau correspondiente, para hacerlo, se hace uso de un función de densidad que ayude a poder calcular la probabilidad acumulada.

```{r}
grafico_tau <- tau_graph%>%
ggplot( aes(x=x)) +
geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.9)+
ylab("Frecuencia") +
xlab("t-statistic")+
theme_ipsum()+
theme(plot.title = element_text(size=15))+
#geom_vline(xintercept = q , linetype=2, color="green")+
ggtitle("Distribución Dickey-Fuller")

grafico_tau <- ggplotly(grafico_tau)
grafico_tau
```
Valor crítico para el Tau-Tau:
```{r}
alpha <- 0.01
x <- sort(DistribucionX3)
cum.dens.fun <- 1:length(x)/length(x)
prob <- (x[which(cum.dens.fun <= alpha)])
VCGammaX3<- prob[length(prob)]
VCGammaX3
```
Estadístico tipo t de Gamma:
```{r}
estadisticoX3Gamma <- GammaX3/(sqrt(VarcovX3[3,3]))
estadisticoX3Gamma
```
En este caso, la hipótesis nula es que gamma es estadísticamente igual a cero, por lo tanto, en la hipótesis nula gamma, es estadísticamente diferente de cero. Con el resultado anterior, caemos en la hipótesis nula, por ende existe raíz unitaria.

Ahora concluimos sobre la tendencia y el intercepto comparando con el estadístico tipo t de cada coeficiente con el valor crítico de un t con t-k grados de libertad.

Estadístico tipo t de Beta:
```{r}
estadisticoX3Beta <- BetaX3/(sqrt(VarcovX3[2,2]))
estadisticoX3Beta

VCBetaX3 <- qt((1-alpha),(n/4))
VCBetaX3
```
En este caso, la tendencia es significativa. Por ende, el esquema adecuado es el 3 y me encuentro en un DGP4.

La serie siguiente serie a evaluar es Yt emepzando de nuevo sobre el esquema más amplio.

$$
\Delta Y_t=\alpha +\beta t+\gamma Y_{t-1}+\varepsilon_t
$$

Ya teniendo el nuevo esquema, sin la parte aumentada, es necesario estimar por OLS y hallar la significancia de cada coeficiente. Se empezará por el gamma, que nos diría si hay o no hay raíz unitaria.

```{r}
p <- 1
Y_t_menos_1 <- c()
for (i in 1:n) {
Y_t_menos_1[i] <- SerieY_t[i-1]
}
N3 <- length(Y_t_menos_1)-1
#creo el delta
DeltaY<- c()
for (i in 1:n) {
DeltaY[i]<- SerieY_t[i]-Y_t_menos_1[i]
}

DeltaY_cuchilla <- as.matrix(DeltaY[(p+1):length(DeltaY)])
#Estimacion
X_Y3DF <- matrix(0,N3,p+2)
X_Y3DF[,1]=1 #Intercepto
X_Y3DF[,2]=1:length(X_Y3DF[,1]) #Tendencia
X_Y3DF[,3]=SerieY_t[(p+1):length(SerieY_t)-1] #Rezago de la serie

BetasY3 <- solve(as.matrix(t(X_Y3DF)%*%X_Y3DF))%*%t(X_Y3DF)%*%DeltaY_cuchilla
Yestimado3 <- X_Y3DF%*%BetasY3
ResidualesY3 <- DeltaY_cuchilla-Yestimado3
SigmaY3 <- as.numeric(t(ResidualesY3)%*%ResidualesY3)/(length(DeltaY_cuchilla)-ncol(X_Y3DF))
VarcovY3 <- SigmaY3*(solve(t(X_Y3DF)%*%X_Y3DF))

AlphaY3 <- BetasY3[1]
BetaY3 <- BetasY3[2]
GammaY3 <- BetasY3[3]
```

Pruebo la significancia del gamma con ayuda de los valores críticos simulados de los Taus.

Simulaciones de los Taus, se realizan por medio de una función:

```{r}
#tau toma el valor de 1, es distribución tau, 2 es distribución tau-mu y 3 si es distribución tau-tau
#En este caso, se toma tau-tau porque estamos en el tercer esquema 
DistribucionY3 <- Distribucion_tau(200,1000,3)
tau_graph <- data.frame(y=DistribucionY3)

grafico_tau <- tau_graph%>%
ggplot( aes(x=y)) +
geom_histogram(binwidth=0.3, fill="#69b3a2", color="#e9ecef", alpha=0.9)+
ylab("Frecuencia") +
xlab("t-statistic")+
theme_ipsum()+
theme(plot.title = element_text(size=15))+
#geom_vline(xintercept = q , linetype=2, color="green")+
ggtitle("Distribución Dickey-Fuller")

grafico_tau <- ggplotly(grafico_tau)
grafico_tau
```

Calculamos el valor critico de acuerdo al tau correspondiente, para hacerlo, se hace uso de un función de densidad que ayude a poder calcular la probabilidad acumulada.

```{r}
grafico_tau <- tau_graph%>%
ggplot( aes(x=y)) +
geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.9)+
ylab("Frecuencia") +
xlab("t-statistic")+
theme_ipsum()+
theme(plot.title = element_text(size=15))+
#geom_vline(xintercept = q , linetype=2, color="green")+
ggtitle("Distribución Dickey-Fuller")

grafico_tau <- ggplotly(grafico_tau)
grafico_tau
```
Valor crítico para el Tau-Tau:
```{r}
alpha <- 0.01
x <- sort(DistribucionY3)
cum.dens.fun <- 1:length(x)/length(x)
prob <- (x[which(cum.dens.fun <= alpha)])
VCGammaY3<- prob[length(prob)]
VCGammaY3
```
Estadístico tipo t de Gamma:
```{r}
estadisticoY3Gamma <- GammaY3/(sqrt(VarcovY3[3,3]))
estadisticoY3Gamma
```

Ahora concluimos sobre la tendencia y el intercepto comparando con el estadístico tipo t de cada coeficiente con el valor crítico de un t con t-k grados de libertad.

Estadístico tipo t de Beta:
```{r}
estadisticoY3Beta <- BetaY3/(sqrt(VarcovY3[2,2]))
estadisticoY3Beta

VCBetaY3 <- qt((1-alpha),(n/4))
VCBetaY3
```
En este caso, la tendencia no es significativa. Por ende, es necesario bajarnos de esquema.
$$
\Delta Y_t=\alpha +\gamma Y_{t-1}+\varepsilon_t
$$

```{r}
p <- 1
Y_t_menos_1 <- c()
for (i in 1:n) {
Y_t_menos_1[i] <- SerieY_t[i-1]
}
N3 <- length(Y_t_menos_1)-1
#creo el delta
DeltaY<- c()
for (i in 1:n) {
DeltaY[i]<- SerieY_t[i]-Y_t_menos_1[i]
}

DeltaY_cuchilla <- as.matrix(DeltaY[(p+1):length(DeltaY)])
#Estimacion
X_Y3DF <- matrix(0,N3,p+1)
X_Y3DF[,1]=1 #Intercepto
X_Y3DF[,2]=SerieY_t[(p+1):length(SerieY_t)-1] #Rezago de la serie

BetasY3 <- solve(as.matrix(t(X_Y3DF)%*%X_Y3DF))%*%t(X_Y3DF)%*%DeltaY_cuchilla
Yestimado3 <- X_Y3DF%*%BetasY3
ResidualesY3 <- DeltaY_cuchilla-Yestimado3
SigmaY3 <- as.numeric(t(ResidualesY3)%*%ResidualesY3)/(length(DeltaY_cuchilla)-ncol(X_Y3DF))
VarcovY3 <- SigmaY3*(solve(t(X_Y3DF)%*%X_Y3DF))

AlphaY3 <- BetasY3[1]
GammaY3 <- BetasY3[2]
```

Mirar la significancia del gamma para ver si cumple o no con raíz unitaria.

```{r}
#tau toma el valor de 1, es distribución tau, 2 es distribución tau-mu y 3 si es distribución tau-tau
#En este caso, se toma tau-mu porque estamos en el segundo esquema 
DistribucionY3 <- Distribucion_tau(200,1000,2)
tau_graph <- data.frame(y=DistribucionY3)

grafico_tau <- tau_graph%>%
ggplot( aes(x=y)) +
geom_histogram(binwidth=0.3, fill="#69b3a2", color="#e9ecef", alpha=0.9)+
ylab("Frecuencia") +
xlab("t-statistic")+
theme_ipsum()+
theme(plot.title = element_text(size=15))+
#geom_vline(xintercept = q , linetype=2, color="green")+
ggtitle("Distribución Dickey-Fuller")

grafico_tau <- ggplotly(grafico_tau)
grafico_tau
```

Calculamos el valor critico de acuerdo al tau correspondiente, para hacerlo, se hace uso de un función de densidad que ayude a poder calcular la probabilidad acumulada.

```{r}
grafico_tau <- tau_graph%>%
ggplot( aes(x=y)) +
geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.9)+
ylab("Frecuencia") +
xlab("t-statistic")+
theme_ipsum()+
theme(plot.title = element_text(size=15))+
#geom_vline(xintercept = q , linetype=2, color="green")+
ggtitle("Distribución Dickey-Fuller")

grafico_tau <- ggplotly(grafico_tau)
grafico_tau
```
Valor crítico para el Tau-Tau:
```{r}
alpha <- 0.01
x <- sort(DistribucionY3)
cum.dens.fun <- 1:length(x)/length(x)
prob <- (x[which(cum.dens.fun <= alpha)])
VCGammaY3<- prob[length(prob)]
VCGammaY3
```
Estadístico tipo t de Gamma:
```{r}
estadisticoY3Gamma <- GammaY3/(sqrt(VarcovY3[2,2]))
estadisticoY3Gamma
```
Con el resultado anterior, caemos en la hipótesis nula, por ende existe raíz unitaria.

Ahora, es necesario verificar la significancia del intercepto.

```{r}

estadisticoY3Alpha <- AlphaY3/(sqrt(VarcovY3[1,1]))
estadisticoY3Alpha

VCAlphaY3 <- qt((1-alpha),(n/4))
VCAlphaY3
```
Con el resultado anterior, caemos en la hipótesis nula, por ende el intercepto  no es significativo.Es necesario bajarme de esquema.

$$
\Delta Y_t=\gamma Y_{t-1}+\varepsilon_t
$$
Estimo por OLS para hallar el gamma estimado y poder concluir

```{r}
p <- 1
Y_t_menos_1 <- c()
for (i in 1:n) {
Y_t_menos_1[i] <- SerieY_t[i-1]
}
N3 <- length(Y_t_menos_1)-1
#creo el delta
DeltaY<- c()
for (i in 1:n) {
DeltaY[i]<- SerieY_t[i]-Y_t_menos_1[i]
}

DeltaY_cuchilla <- as.matrix(DeltaY[(p+1):length(DeltaY)])
#Estimacion
X_Y3DF <- matrix(0,N3,p)
X_Y3DF[,1]=SerieY_t[(p+1):length(SerieY_t)-1] #Rezago de la serie

BetasY3 <- solve(as.matrix(t(X_Y3DF)%*%X_Y3DF))%*%t(X_Y3DF)%*%DeltaY_cuchilla
Yestimado3 <- X_Y3DF%*%BetasY3
ResidualesY3 <- DeltaY_cuchilla-Yestimado3
SigmaY3 <- as.numeric(t(ResidualesY3)%*%ResidualesY3)/(length(DeltaY_cuchilla)-ncol(X_Y3DF))
VarcovY3 <- SigmaY3*(solve(t(X_Y3DF)%*%X_Y3DF))

GammaY3 <- BetasY3[1]

```

Pruebo la significancia del gamma con ayuda de los valores críticos simulados de los Taus.

Simulaciones de los Taus, se realizan por medio de una función:

```{r}
#tau toma el valor de 1, es distribución tau, 2 es distribución tau-mu y 3 si es distribución tau-tau
#En este caso, se toma tau porque estamos en el primer esquema 
DistribucionY3 <- Distribucion_tau(200,1000,1)
tau_graph <- data.frame(y=DistribucionY3)

grafico_tau <- tau_graph%>%
ggplot( aes(x=y)) +
geom_histogram(binwidth=0.3, fill="#69b3a2", color="#e9ecef", alpha=0.9)+
ylab("Frecuencia") +
xlab("t-statistic")+
theme_ipsum()+
theme(plot.title = element_text(size=15))+
#geom_vline(xintercept = q , linetype=2, color="green")+
ggtitle("Distribución Dickey-Fuller")

grafico_tau <- ggplotly(grafico_tau)
grafico_tau
```

Calculamos el valor critico de acuerdo al tau correspondiente, para hacerlo, se hace uso de un función de densidad que ayude a poder calcular la probabilidad acumulada.

```{r}
grafico_tau <- tau_graph%>%
ggplot( aes(x=y)) +
geom_density(fill="#69b3a2", color="#e9ecef", alpha=0.9)+
ylab("Frecuencia") +
xlab("t-statistic")+
theme_ipsum()+
theme(plot.title = element_text(size=15))+
#geom_vline(xintercept = q , linetype=2, color="green")+
ggtitle("Distribución Dickey-Fuller")

grafico_tau <- ggplotly(grafico_tau)
grafico_tau
```
Valor crítico para el Tau-Tau:
```{r}
alpha <- 0.01
x <- sort(DistribucionY3)
cum.dens.fun <- 1:length(x)/length(x)
prob <- (x[which(cum.dens.fun <= alpha)])
VCGammaY3<- prob[length(prob)]
VCGammaY3
```
Estadístico tipo t de Gamma:
```{r}
estadisticoY3Gamma <- GammaY3/(sqrt(VarcovY3[1,1]))
estadisticoY3Gamma
```
Como en este caso, la hipótesis nula es que gamma es estadísticamente igual a cero, por lo tanto, en la hipótesis nula gamma, es estadísticamente diferente de cero. Con el resultado anterior, caemos en la hipótesis nula, por ende existe raíz unitaria.


Prueba tipo Dickey Fuller sobre los residuales 
Como los residuales son I(0), existe cointegración.Además, el Teorema de Representación de Granger afirma que si un vector de variables Y_t de dimensión nx1 donde Y_t es CI(1,1) entonces existe un Mecanismo de Corrección de Error (MCE) que representa de la manera más adecuada al Proceso Generador de Datos (DGP) subyacente.

Estimación por OLS del siguiente modelo:

$$
W_t=\beta_0+\beta_1X_t+\beta_2Y_t+e_t
$$
*Probando cointegración*

```{r}
auxiliar <- lm(SerieW_t~SerieX_t+SerieY_t)
Betasaux <- auxiliar$coefficients
Betasaux
```
Dickey Fuller a la regresión auxiliar

```{r}
residualesaux <- auxiliar$residuals
adf.test(residualesaux)
```
Teniendo los residuales son I(0), se sabe que existe cointegración, siendo el vector (W_t,-X_t,-Y_t)

### 2.3 Calcular el MCE

El Mecanismo de Corrección de Error combina información de corto plazo con el largo plazo. Se convierte en un sistema de información que permite seleccionar la ecuación objetivo de estudio.En nuestra simulación, el sistema es el siguiente:
$$
\begin{equation}
\begin{bmatrix}
\Delta X_t\\
\Delta Y_t\\
\Delta W_t
\end{bmatrix}=
\begin{bmatrix}
\delta_{01}\\
\delta_{02}\\
\delta_{03}
\end{bmatrix}
\begin{bmatrix}
\ a_{11,1}&a_{12,1}&a_{13,1}\\
\ a_{21,1}&a_{22,1}&a_{23,1}\\
\ a_{31,1}&a_{32,1}&a_{33,1}
\end{bmatrix}
\begin{bmatrix}
\Delta X_{t-1}\\
\Delta Y_{t-1}\\
\Delta W_{t-1}
\end{bmatrix}+...+
\begin{bmatrix}
\ a_{11,p}&a_{12,p}&a_{13,p}\\
\ a_{21,p}&a_{22,p}&a_{23,p}\\
\ a_{31,p}&a_{32,p}&a_{33,p}
\end{bmatrix}-
\begin{bmatrix}
\Delta X_{t-p}\\
\Delta Y_{t-p}\\
\Delta W_{t-p}
\end{bmatrix}-
\begin{bmatrix}
\alpha_1\\
\alpha_2\\
\alpha_3
\end{bmatrix}
\begin{bmatrix}
\hat{Z_{t-1}}
\end{bmatrix}+
\begin{bmatrix}
\varepsilon_{xt}\\
\varepsilon_{yt}\\
\varepsilon_{wt}
\end{bmatrix}
\end{equation} \\
$$


Determinando la variable endógena como W_t se obtiene del sistema mutivariado, el siguiente sistema univariado:
$$
\Delta W_{t}=\delta_{01}+a_{11,1}\Delta W_{t-1}+a_{12,1}\Delta W_{t-1}+a_{13,1}\Delta W_{t-1}+...+a_{11,p}Delta W_{t-p}+a_{12,p}Delta W_{t-p}+a_{13,p}Delta W_{t-p}-\alpha_1\hat{Z_{t-1}}+\varepsilon_{xt}
$$
En este caso el número de rezagos es 1:
```{r}
#Creo los deltas correspondientes a cada serie
Zestimado <- residualesaux
Delta_X <- SerieX_t[2:n]-SerieX_t[1:(n-1)]
Delta_Y <- SerieY_t[2:n]-SerieY_t[1:(n-1)]
Delta_W <- SerieW_t[2:n]-SerieW_t[1:(n-1)]
#Construyo la matriz de diseño
X <- cbind(1, Delta_X[1:(n-2)],Delta_Y[1:(n-2)],Delta_W[1:(n-2)], Zestimado[2:(n-1)])
#Realizo la estimación con la ayuda del comando lm
estimacion <- lm(Delta_X[1:(n-2)]~X-1)
#Llamo los coeficientes, para ver cual corresponde al alpha estimado
coeficientes <- estimacion$coefficients
alpha1 <- estimacion$coefficients[5]
alpha1
```
Referencias:- Enders, W. (1995). Applied econometric time series. New York: Wiley.
- Stock, J. H., & Watson, M. W. (2007). Introduction to econometrics. Boston: Pearson/Addison Wesley.
- Engle, R. and Granger, C. (1987) Cointegration and Error Correction: Representation, Estimation and Testing. Econometrica, 55, 251-276.











